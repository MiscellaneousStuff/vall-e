{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `G2P` and `EnCodec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install g2p_en encodec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `G2P`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import string\n",
    "from functools import cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "@cache\n",
    "def _get_model():\n",
    "    return G2p()\n",
    "\n",
    "@cache\n",
    "def _get_graphs(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        graphs = f.read()\n",
    "    return graphs\n",
    "\n",
    "def encode(graphs: str) -> list[str]:\n",
    "    g2p = _get_model()\n",
    "    phones = g2p(graphs)\n",
    "    ignored = {\" \", *string.punctuation}\n",
    "    return [\"_\" if p in ignored else p for p in phones]\n",
    "\n",
    "@torch.no_grad()\n",
    "def write_phones(folder, suffix=\".normalized.txt\"):\n",
    "    print(\"ello?\")\n",
    "    paths = list(folder.rglob(f\"*{suffix}\"))\n",
    "    random.shuffle(paths)\n",
    "\n",
    "    print(\"paths:\", paths)\n",
    "    for path in tqdm(paths):\n",
    "        phone_path = path.with_name(path.stem.split(\".\")[0] + \".phn.txt\")\n",
    "        if phone_path.exists():\n",
    "            continue\n",
    "        print(\"?\")\n",
    "        graphs = _get_graphs(path)\n",
    "        phones = encode(graphs)\n",
    "        with open(phone_path, \"w\") as f:\n",
    "            f.write(\" \".join(phones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ello?\n",
      "paths: [WindowsPath('data/text/test.normalized.txt')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "write_phones(Path(\"./data/text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Encodec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "from functools import cache\n",
    "import torchaudio\n",
    "from encodec import EncodecModel\n",
    "from torch import Tensor\n",
    "from einops import rearrange\n",
    "import soundfile\n",
    "from encodec.utils import convert_audio\n",
    "from pathlib import Path\n",
    "\n",
    "SAMPLE_RATE = 24_000\n",
    "BANDWIDTHS  = [1.5, 3.0, 6.0, 12.0, 24.0]\n",
    "BANDWIDTH   = BANDWIDTHS[0]\n",
    "\n",
    "@cache\n",
    "def _load_model(bandwidth=6.0, device=\"cuda\"):\n",
    "    # Instantiate a pretrained EnCodec model\n",
    "    assert SAMPLE_RATE == 24_000\n",
    "    model = EncodecModel.encodec_model_24khz()\n",
    "    model.set_target_bandwidth(bandwidth)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def unload_model():\n",
    "    return _load_model.cache_clear()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def decode(codes: Tensor, bandwidth=6.0, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        codes: (b q t)\n",
    "    \"\"\"\n",
    "    assert codes.dim() == 3\n",
    "    model = _load_model(bandwidth, device)\n",
    "    return model.decode([(codes, None)]), model.sample_rate\n",
    "\n",
    "def decode_to_file(resps: Tensor, path: Path):\n",
    "    assert resps.dim() == 2, f\"Require shape (t q), but got {resps.shape}.\"\n",
    "    resps = rearrange(resps, \"t q -> 1 q t\")\n",
    "    wavs, sr = decode(codes=resps, bandwidth=BANDWIDTH)\n",
    "    soundfile.write(str(path), wavs.cpu()[0, 0], sr)\n",
    "\n",
    "def _replace_file_extension(path, suffix):\n",
    "    return (path.parent / path.name.split(\".\")[0]).with_suffix(suffix)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode(wav: Tensor, sr: int, bandwidth=6.0, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        wav: (t)\n",
    "        sr: int\n",
    "    \"\"\"\n",
    "    model = _load_model(bandwidth, device)\n",
    "    wav = wav.unsqueeze(0)\n",
    "    wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
    "    wav = wav.to(device)\n",
    "    encoded_frames = model.encode(wav)\n",
    "    qnt = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # (b q t)\n",
    "    return qnt\n",
    "\n",
    "def encode_from_file(path, bandwidth=6.0, device=\"cuda\"):\n",
    "    wav, sr = torchaudio.load(str(path))\n",
    "    if wav.shape[0] == 2:\n",
    "        wav = wav[:1]\n",
    "    return encode(wav, sr, bandwidth, device)\n",
    "\n",
    "def quantize_audio(folder, suffix=\".wav\"):\n",
    "    paths = [*folder.rglob(f\"*{suffix}\")]\n",
    "    random.shuffle(paths)\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        out_path = _replace_file_extension(path, \".qnt.pt\")\n",
    "        if out_path.exists():\n",
    "            continue\n",
    "        qnt = encode_from_file(path, BANDWIDTH)\n",
    "        print(qnt.shape)\n",
    "        torch.save(qnt.cpu(), out_path)\n",
    "\n",
    "def decode_files(folder, suffix=\".qnt.pt\"):\n",
    "    paths = [*folder.rglob(f\"*{suffix}\")]\n",
    "    random.shuffle(paths)\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        out_path = _replace_file_extension(path, \".qt.wav\")\n",
    "        if out_path.exists():\n",
    "            continue\n",
    "        fi = rearrange(torch.load(path).squeeze(0).cuda(), \"q t -> t q\")\n",
    "        decode_to_file(fi, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LJSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDWIDTH_IDX = 1 # original VALL-E\n",
    "CODEBOOKS     = [2, 4, 8, 16, 32]\n",
    "BANDWIDTHS    = [1.5, 3.0, 6.0, 12.0, 24.0]\n",
    "BANDWIDTH     = BANDWIDTHS[BANDWIDTH_IDX]\n",
    "CODEBOOK      = CODEBOOKS[BANDWIDTH_IDX]\n",
    "\n",
    "import torchaudio\n",
    "from ljspeech import LJSPEECH\n",
    "DATASET_PATH = \"./data/LJSpeech/\"\n",
    "dataset = LJSPEECH(\n",
    "    \"./data/LJSpeech\",\n",
    "    encodec_bandwidth=BANDWIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 725])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.1, random_state=42)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, collate_fn=lambda x: x)\n",
    "test_loader = DataLoader(dataset, batch_size=32, sampler=test_sampler, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
